{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.15"},"colab":{"name":"MODELO_MACHINE_LEARNING.ipynb","provenance":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"vQKVy7lbk3sz","colab_type":"text"},"source":["### Modelo de Machine Learning Supervisado\n","\n","En este último Notebook usaré **XGBoost** para predecir los productos que reordenarán los usuarios creando un modelo de predicción supervisado. para ello he **definido unas funciones** que me ayudarán a agrupar las acciones que ejecutaré durante este notebook.\n","\n","En primer lugar cargamos algunad de las librerías que resultan utiles para cargar los ficheros:\n","\n","* gc\n","\n","* time\n","\n","* numpy\n","\n","* pandas\n","\n","* sklearn\n"]},{"cell_type":"code","metadata":{"id":"EMt03SMVfGX6","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MJyAh1Msk3s0","colab_type":"code","colab":{}},"source":["# Este entorno de Python 3 viene con muchas bibliotecas de análisis útiles instaladas\n","# Por ejemplo, aquí hay varios paquetes útiles para cargar\n","import gc\n","import time\n","import numpy as np # Algebre lineal\n","import pandas as pd # procesamiento de datos, CSV file I/O (e.g. pd.read_csv)\n","from sklearn.model_selection import train_test_split\n","\n","# Los archivos de datos de entrada están disponibles en el directorio \"DATOS\"."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i5Nu4p-Kk3s3","colab_type":"text"},"source":["### Funcion para cargar los datos\n","Mediante la función read_csv de Pandas iré cargando las distintas tablas\n","\n","Para la generación de un modelo más eficiente necesito controlar el tipo de los datos por eso voy a usar la librería numpy para ello."]},{"cell_type":"code","metadata":{"id":"u8dL6Yvrk3s4","colab_type":"code","colab":{}},"source":["def load_data(path_data):\n","\n","    #--------------------------------order_product--------------------------------\n","    # Ordenes ya conocidas\n","    priors = pd.read_csv(path_data + 'order_products__prior.csv', \n","                     dtype={\n","                            'order_id': np.int32,\n","                            'product_id': np.uint16,\n","                            'add_to_cart_order': np.int16,\n","                            'reordered': np.int8})\n","    # Ordenes de entrenamiento\n","    train = pd.read_csv(path_data + 'order_products__train.csv', \n","                    dtype={\n","                            'order_id': np.int32,\n","                            'product_id': np.uint16,\n","                            'add_to_cart_order': np.int16,\n","                            'reordered': np.int8})\n","    \n","    #--------------------------------orden----------------- ---------------\n","    # Este archivo nos dice a qué conjunto (conocido, train, test) pertenece una orden\n","    # Único en order_id\n","    # order_id en train, prior\n","    # Este es el orden #order_number de este usuario\n","    \n","    orders = pd.read_csv(path_data + 'orders.csv', \n","                         dtype={\n","                                'order_id': np.int32,\n","                                'user_id': np.int64,\n","                                'eval_set': 'category',\n","                                'order_number': np.int16,\n","                                'order_dow': np.int8,\n","                                'order_hour_of_day': np.int8,\n","                                'days_since_prior_order': np.float32})\n","\n","    \n","    #--------------------------------product--------------------------------\n","    \n","    products = pd.read_csv(path_data + 'products.csv')\n","    aisles = pd.read_csv(path_data + \"aisles.csv\")\n","    departments = pd.read_csv(path_data + \"departments.csv\")\n","    sample_submission = pd.read_csv(path_data + \"sample_submission.csv\")\n","    \n","    return priors, train, orders, products, aisles, departments, sample_submission\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F4souNwlk3s7","colab_type":"text"},"source":["#### Clase tick_tock\n","\n","La usaré en las siguientes funciones para agregar los datos."]},{"cell_type":"code","metadata":{"id":"dE5ME_tZk3s8","colab_type":"code","colab":{}},"source":["class tick_tock:\n","    def __init__(self, process_name, verbose=1):\n","        self.process_name = process_name\n","        self.verbose = verbose\n","    def __enter__(self):\n","        if self.verbose:\n","            print(self.process_name + \" begin ......\")\n","            self.begin_time = time.time()\n","    def __exit__(self, type, value, traceback):\n","        if self.verbose:\n","            end_time = time.time()\n","            print(self.process_name + \" end ......\")\n","            print('time lapsing {0} s \\n'.format(end_time - self.begin_time))\n","            \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WCLBXhf6k3s_","colab_type":"text"},"source":["### Funcion 1 Vs N\n","\n","**Parametros de entrada**: \n","\n","* df = DataFrame de Pandas (priors_orders_detail)\n","\n","* group_columns_list = Lista de columnas que desea agrupar, podrían ser múltiples columnas (User_ID)\n","\n","* agg_dict = diccionario de python\n","\n","**Devuelve**:\n","\n","Nuevo marco de datos de pandas con columnas originales y nuevas columnas agregadas. \n","(df_new)\n","\n","**Ejemplo:**\n","\n","\n","       {real_column_name: {Nombre_de_las_nuevas_columnas : method}}\n","       agg_dict = {'user_id':{'prod_tot_cnts':'count'},\n","                   'reordered':{'reorder_tot_cnts_of_this_prod':'sum'},\n","                   'user_buy_product_times': {'prod_order_once':lambda x: sum(x==1),\n","                                              'prod_order_more_than_once':lambda x: sum(x==2)}}\n","       ka_add_stats_features_1_vs_n(train, ['product_id'], agg_dict)\n","\n","###### Proceso:\n","Crear columnas estadísticas, agrupar por [N columnas] y calcular estadísticas en [columna N]\n","\n","* 1º Agrupa por usuario el Data Frame\n","* 2º Agg es un alias para Aggregate --> Por lo que agregamos lo que pasemos en agg_dict\n","* 3º Elimino la cabecera\n","* 4º Reindexo\n","* 5º Por ultimo uno las tablas con un merge\n","* 6º La funcion devuelve el ultimo dataframe"]},{"cell_type":"code","metadata":{"id":"BSUeUF1Ek3tA","colab_type":"code","colab":{}},"source":["def ka_add_groupby_features_1_vs_n(df, group_columns_list, agg_dict, only_new_feature=True):\n","    \n","    with tick_tock(\"add stats features\"):\n","        try:\n","            if type(group_columns_list) == list:\n","                pass\n","            else:\n","                raise TypeError(k + \"should be a list\")\n","        except TypeError as e:\n","            print(e)\n","            raise\n","\n","        df_new = df.copy()\n","        grouped = df_new.groupby(group_columns_list)\n","\n","        the_stats = grouped.agg(agg_dict)\n","        the_stats.columns = the_stats.columns.droplevel(0)\n","        the_stats.reset_index(inplace=True)\n","        if only_new_feature:\n","            df_new = the_stats\n","        else:\n","            df_new = pd.merge(left=df_new, right=the_stats, on=group_columns_list, how='left')\n","\n","    return df_new\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bk5aAoU6k3tC","colab_type":"text"},"source":["### Funcion N Vs 1\n","\n","**Parametros de entrada:** \n","\n","* df = marco de datos pandas Matriz de características (priors_orders_detail)\n","\n","* group_columns_list = Lista de columnas que desea agrupar, podría ser varias columnas (User_ID)\n","\n","* target_columns_list = columna que desea calcular las estadísticas, debe ser una lista con un solo elemento\n","\n","* methods_list = Métodos que desea utilizar, todos los métodos compatibles con groupby en Pandas\n","\n","* agg_dict\n","\n","**Devuelve:**\n","Nuevo marco de datos de pandas con columnas originales y nuevas columnas agregadas.\n","(df_new)\n","\n","**Ejemplo:**\n","\n"," ka_add_stats_features_n_vs_1 (train, group_columns_list = ['x0'], target_columns_list = ['x10'])\n","\n","###### Proceso:\n","\n"]},{"cell_type":"code","metadata":{"id":"n9ijJEMQk3tC","colab_type":"code","colab":{}},"source":["def ka_add_groupby_features_n_vs_1(df, group_columns_list, target_columns_list, methods_list, keep_only_stats=True, verbose=1):\n","#Aquí hago uso de la clase tick_tock definida previamente\n","    with tick_tock(\"add stats features\", verbose):\n","        dicts = {\"group_columns_list\": group_columns_list , \"target_columns_list\": target_columns_list, \"methods_list\" :methods_list}\n","\n","        for k, v in dicts.items():\n","            try:\n","                if type(v) == list:\n","                    pass\n","                else:\n","                    raise TypeError(k + \"should be a list\")\n","            except TypeError as e:\n","                print(e)\n","                raise\n","\n","        grouped_name = ''.join(group_columns_list)\n","        target_name = ''.join(target_columns_list)\n","        combine_name = [[grouped_name] + [method_name] + [target_name] for method_name in methods_list]\n","\n","        df_new = df.copy()\n","        grouped = df_new.groupby(group_columns_list)\n","\n","        the_stats = grouped[target_name].agg(methods_list).reset_index()\n","        the_stats.columns = [grouped_name] + \\\n","                            ['_%s_%s_by_%s' % (grouped_name, method_name, target_name) \\\n","                             for (grouped_name, method_name, target_name) in combine_name]\n","        if keep_only_stats:\n","            return the_stats\n","        else:\n","            df_new = pd.merge(left=df_new, right=the_stats, on=group_columns_list, how='left')\n","        return df_new"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-BO5QGv2k3tF","colab_type":"text"},"source":["**Cargo los datos parametrizados** para la cual he utilizado la funcion previamente definida"]},{"cell_type":"code","metadata":{"id":"nTLWpkaNk3tG","colab_type":"code","colab":{}},"source":["path_data = 'DATOS/'\n","priors, train, orders, products, aisles, departments, sample_submission = load_data(path_data)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sFrTNPt1k3tI","colab_type":"text"},"source":["# Estudio de los productos\n","\n","Para el estudio de los productos voy a **crear nuevas variables**, para identificarlas las he puesto un \"_\" al principio de la variable\n","\n","#### GRUPO DE VARIABLES 1\n","\n","* prod_buy_second_time_total_cnt : Productos que se han re-comprado alguna vez\n","* prod_buy_first_time_total_cnt: Productos que se han comprado alguna vez\n","* prod_tot_cnts: Usuarios distintos que han comprado algún producto\n","* prod_reorder_prob: % de productos que han sido reordenados frente a los que no\n","* prod_reorder_ratio: % de productos que han sido reordenados del total de pedidos\n","* prod_reorder_times: % de veces que los productos han sido reordenados del total de pedidos"]},{"cell_type":"code","metadata":{"id":"4YGffLBJk3tI","colab_type":"code","colab":{},"outputId":"da699659-7221-418a-e172-75dbc31bdfb1"},"source":["# Información de productos ----------------------------------------------------------------\n","# Agregar información del pedido a los priors establecidos\n","priors_orders_detail = orders.merge(right=priors, how='inner', on='order_id')\n","\n","# Creacion de nuevas variables\n","priors_orders_detail.loc[:,'_user_buy_product_times'] = priors_orders_detail.groupby(['user_id', 'product_id']).cumcount() + 1\n","agg_dict = {'user_id':{'_prod_tot_cnts':'count'}, \n","            'reordered':{'_prod_reorder_tot_cnts':'sum'}, \n","            '_user_buy_product_times': {'_prod_buy_first_time_total_cnt':lambda x: sum(x==1),\n","                                        '_prod_buy_second_time_total_cnt':lambda x: sum(x==2)}}\n","\n","# Uso de la función 1 Vs n para añadir las variables creadas a priors_orders_detail:\n","prd = ka_add_groupby_features_1_vs_n(priors_orders_detail, ['product_id'], agg_dict)\n","\n","# Una vez agregadas las nuevas variables, genero unos ratios que me serán útiles para los calculos\n","prd['_prod_reorder_prob'] = prd._prod_buy_second_time_total_cnt / prd._prod_buy_first_time_total_cnt\n","prd['_prod_reorder_ratio'] = prd._prod_reorder_tot_cnts / prd._prod_tot_cnts\n","prd['_prod_reorder_times'] = 1 + prd._prod_reorder_tot_cnts / prd._prod_buy_first_time_total_cnt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["add stats features begin ......\n"],"name":"stdout"},{"output_type":"stream","text":["C:\\Users\\alejandro.ortega.or1\\anaconda\\lib\\site-packages\\pandas\\core\\groupby.py:4036: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n","  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"],"name":"stderr"},{"output_type":"stream","text":["add stats features end ......\n","time lapsing 268.706999779 s \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0UD-bDuSk3tL","colab_type":"code","colab":{},"outputId":"18615b72-5170-4240-cff3-a7cd4c512f30"},"source":["prd.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style>\n","    .dataframe thead tr:only-child th {\n","        text-align: right;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: left;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>product_id</th>\n","      <th>_prod_buy_second_time_total_cnt</th>\n","      <th>_prod_buy_first_time_total_cnt</th>\n","      <th>_prod_tot_cnts</th>\n","      <th>_prod_reorder_tot_cnts</th>\n","      <th>_prod_reorder_prob</th>\n","      <th>_prod_reorder_ratio</th>\n","      <th>_prod_reorder_times</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>276</td>\n","      <td>716</td>\n","      <td>1852</td>\n","      <td>1136.0</td>\n","      <td>0.385475</td>\n","      <td>0.613391</td>\n","      <td>2.586592</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>78</td>\n","      <td>90</td>\n","      <td>12.0</td>\n","      <td>0.102564</td>\n","      <td>0.133333</td>\n","      <td>1.153846</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>36</td>\n","      <td>74</td>\n","      <td>277</td>\n","      <td>203.0</td>\n","      <td>0.486486</td>\n","      <td>0.732852</td>\n","      <td>3.743243</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>64</td>\n","      <td>182</td>\n","      <td>329</td>\n","      <td>147.0</td>\n","      <td>0.351648</td>\n","      <td>0.446809</td>\n","      <td>1.807692</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>15</td>\n","      <td>9.0</td>\n","      <td>0.666667</td>\n","      <td>0.600000</td>\n","      <td>2.500000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   product_id  _prod_buy_second_time_total_cnt  \\\n","0           1                              276   \n","1           2                                8   \n","2           3                               36   \n","3           4                               64   \n","4           5                                4   \n","\n","   _prod_buy_first_time_total_cnt  _prod_tot_cnts  _prod_reorder_tot_cnts  \\\n","0                             716            1852                  1136.0   \n","1                              78              90                    12.0   \n","2                              74             277                   203.0   \n","3                             182             329                   147.0   \n","4                               6              15                     9.0   \n","\n","   _prod_reorder_prob  _prod_reorder_ratio  _prod_reorder_times  \n","0            0.385475             0.613391             2.586592  \n","1            0.102564             0.133333             1.153846  \n","2            0.486486             0.732852             3.743243  \n","3            0.351648             0.446809             1.807692  \n","4            0.666667             0.600000             2.500000  "]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"ypaRfhgsk3tN","colab_type":"text"},"source":["Ahora se puede ordenar los productos por el ratio de reordenados para ver que productos tienen más probabilidad de ser reodenados por el usuario"]},{"cell_type":"markdown","metadata":{"id":"X0WwnoFDk3tO","colab_type":"text"},"source":["# Estudio de los usuarios\n","\n","Para el estudio de los usuarios también voy a **crear variables que puedan resultar útiles para el modelo**\n","\n","\n","#### GRUPO DE VARIABLES 2\n","\n","* user_mean_days_since_prior_order: Distancia desde la última compra (promedio)\n","* user_sum_days_since_prior_order: Desde el último momento de la compra, esto solo se puede calcular en la tabla de pedidos\n","* user_total_orders: Total de ordenes de cada uno de los usuarios\n","\n","#### GRUPO DE VARIABLES 3\n","\n","\n","* user_total_products: Número total de artículos comprados por el usuario.\n","* user_distinct_products: El número de artículos únicos comprados por el usuario.\n","* user_reorder_ratio:  Número total de veces con reorder / número total de veces después del primer pedido\n","* user_average_basket: Numero de productos por orden de cada usuario"]},{"cell_type":"code","metadata":{"id":"90ory0h6k3tO","colab_type":"code","colab":{},"outputId":"bb38c9c1-6b8d-40f8-ef4d-56cb38b47b0a"},"source":["\n","agg_dict_2 = {'order_number':{'_user_total_orders':'max'},\n","              'days_since_prior_order':{'_user_sum_days_since_prior_order':'sum', \n","                                        '_user_mean_days_since_prior_order': 'mean'}}\n","# Uso de la funcion 1 Vs n para añadir las variables creadas en agg_dict_2\n","users = ka_add_groupby_features_1_vs_n(orders[orders.eval_set == 'prior'], ['user_id'], agg_dict_2)\n","\n","\n","agg_dict_3 = {'reordered':\n","              {'_user_reorder_ratio': \n","               lambda x: sum(priors_orders_detail.loc[x.index,'reordered']==1)/\n","                         sum(priors_orders_detail.loc[x.index,'order_number'] > 1)},\n","              'product_id':{'_user_total_products':'count', \n","                            '_user_distinct_products': lambda x: x.nunique()}}\n","# Uso de la funcion 1 Vs n para añadir las variables creadas en agg_dict_3\n","us = ka_add_groupby_features_1_vs_n(priors_orders_detail, ['user_id'], agg_dict_3)\n","users = users.merge(us, how='inner')\n","\n","# El promedio, número mínimo y máximo de artículos por pedido\n","users['_user_average_basket'] = users._user_total_products / users._user_total_orders\n","\n","us = orders[orders.eval_set != \"prior\"][['user_id', 'order_id', 'eval_set', 'days_since_prior_order']]\n","us.rename(index=str, columns={'days_since_prior_order': 'time_since_last_order'}, inplace=True)\n","\n","users = users.merge(us, how='inner')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["add stats features begin ......\n","add stats features end ......\n","time lapsing 0.37700009346 s \n","\n","add stats features begin ......\n","add stats features end ......\n","time lapsing 447.140000105 s \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EE23xpfqk3tQ","colab_type":"code","colab":{},"outputId":"1a45c445-e05a-4b6b-a49a-345af91c580e"},"source":["users.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style>\n","    .dataframe thead tr:only-child th {\n","        text-align: right;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: left;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>_user_mean_days_since_prior_order</th>\n","      <th>_user_sum_days_since_prior_order</th>\n","      <th>_user_total_orders</th>\n","      <th>_user_total_products</th>\n","      <th>_user_distinct_products</th>\n","      <th>_user_reorder_ratio</th>\n","      <th>_user_average_basket</th>\n","      <th>order_id</th>\n","      <th>eval_set</th>\n","      <th>time_since_last_order</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>19.555555</td>\n","      <td>176.0</td>\n","      <td>10</td>\n","      <td>59</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>5.900000</td>\n","      <td>1187899</td>\n","      <td>train</td>\n","      <td>14.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>15.230769</td>\n","      <td>198.0</td>\n","      <td>14</td>\n","      <td>195</td>\n","      <td>102</td>\n","      <td>0</td>\n","      <td>13.928571</td>\n","      <td>1492625</td>\n","      <td>train</td>\n","      <td>30.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>12.090909</td>\n","      <td>133.0</td>\n","      <td>12</td>\n","      <td>88</td>\n","      <td>33</td>\n","      <td>0</td>\n","      <td>7.333333</td>\n","      <td>2774568</td>\n","      <td>test</td>\n","      <td>11.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>13.750000</td>\n","      <td>55.0</td>\n","      <td>5</td>\n","      <td>18</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>3.600000</td>\n","      <td>329954</td>\n","      <td>test</td>\n","      <td>30.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>13.333333</td>\n","      <td>40.0</td>\n","      <td>4</td>\n","      <td>37</td>\n","      <td>23</td>\n","      <td>0</td>\n","      <td>9.250000</td>\n","      <td>2196797</td>\n","      <td>train</td>\n","      <td>6.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_id  _user_mean_days_since_prior_order  \\\n","0        1                          19.555555   \n","1        2                          15.230769   \n","2        3                          12.090909   \n","3        4                          13.750000   \n","4        5                          13.333333   \n","\n","   _user_sum_days_since_prior_order  _user_total_orders  _user_total_products  \\\n","0                             176.0                  10                    59   \n","1                             198.0                  14                   195   \n","2                             133.0                  12                    88   \n","3                              55.0                   5                    18   \n","4                              40.0                   4                    37   \n","\n","   _user_distinct_products  _user_reorder_ratio  _user_average_basket  \\\n","0                       18                    0              5.900000   \n","1                      102                    0             13.928571   \n","2                       33                    0              7.333333   \n","3                       17                    0              3.600000   \n","4                       23                    0              9.250000   \n","\n","   order_id eval_set  time_since_last_order  \n","0   1187899    train                   14.0  \n","1   1492625    train                   30.0  \n","2   2774568     test                   11.0  \n","3    329954     test                   30.0  \n","4   2196797    train                    6.0  "]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"ZS7w303ok3tS","colab_type":"text"},"source":["# Estudio de los datos\n","\n","Debería haber muchas **variables que se pueden agregar aquí** (Eleccion de Variables).\n","#### GRUPO DE VARIABLES 4\n","\n","* up_average_cart_position: La posición media del artículo añadido a la cesta.\n","* up_order_count: La cantidad de veces que el usuario compró el artículo.\n","* up_first_order_number: El número de pedidos que hizo el usuario para comprar el artículo por primera vez.\n","* up_last_order_number: El número de pedidos que el usuario compró por última vez.\n","* up_order_rate: Ratio de ordenes por usuario\n","* up_order_since_last_order: Ratio de pedido desde la ultima orden\n","* up_order_rate_since_first_order: Ratio de pedido desde la primera orden"]},{"cell_type":"code","metadata":{"id":"oGT9U2TMk3tT","colab_type":"code","colab":{},"outputId":"0ffa573d-169b-493a-8f92-d058c50c9861"},"source":["\n","agg_dict_4 = {'order_number':{'_up_order_count': 'count', \n","                              '_up_first_order_number': 'min', \n","                              '_up_last_order_number':'max'}, \n","              'add_to_cart_order':{'_up_average_cart_position': 'mean'}}\n","\n","# Uso de la funcion 1 Vs n para añadir las variables creadas en agg_dict_4\n","data = ka_add_groupby_features_1_vs_n(df=priors_orders_detail, \n","                                                      group_columns_list=['user_id', 'product_id'], \n","                                                      agg_dict=agg_dict_4)\n","\n","data = data.merge(prd, how='inner', on='product_id').merge(users, how='inner', on='user_id')\n","\n","data['_up_order_rate'] = data._up_order_count / data._user_total_orders\n","data['_up_order_since_last_order'] = data._user_total_orders - data._up_last_order_number\n","data['_up_order_rate_since_first_order'] = data._up_order_count / (data._user_total_orders - data._up_first_order_number + 1)\n","\n","# añado el user_id al set de entrenamiento\n","train = train.merge(right=orders[['order_id', 'user_id']], how='left', on='order_id')\n","data = data.merge(train[['user_id', 'product_id', 'reordered']], on=['user_id', 'product_id'], how='left')\n","\n","del priors_orders_detail, orders\n","gc.collect()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["add stats features begin ......\n","add stats features end ......\n","time lapsing 24.9489998817 s \n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["153"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"uS5hUxPtk3tW","colab_type":"code","colab":{},"outputId":"d8288ea3-878d-48e7-ced4-d3ee33e94d2f"},"source":["data.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style>\n","    .dataframe thead tr:only-child th {\n","        text-align: right;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: left;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>product_id</th>\n","      <th>_up_average_cart_position</th>\n","      <th>_up_order_count</th>\n","      <th>_up_first_order_number</th>\n","      <th>_up_last_order_number</th>\n","      <th>_prod_buy_second_time_total_cnt</th>\n","      <th>_prod_buy_first_time_total_cnt</th>\n","      <th>_prod_tot_cnts</th>\n","      <th>_prod_reorder_tot_cnts</th>\n","      <th>...</th>\n","      <th>_user_distinct_products</th>\n","      <th>_user_reorder_ratio</th>\n","      <th>_user_average_basket</th>\n","      <th>order_id</th>\n","      <th>eval_set</th>\n","      <th>time_since_last_order</th>\n","      <th>_up_order_rate</th>\n","      <th>_up_order_since_last_order</th>\n","      <th>_up_order_rate_since_first_order</th>\n","      <th>reordered</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>196</td>\n","      <td>1.400000</td>\n","      <td>10</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>4660</td>\n","      <td>8000</td>\n","      <td>35791</td>\n","      <td>27791.0</td>\n","      <td>...</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>5.9</td>\n","      <td>1187899</td>\n","      <td>train</td>\n","      <td>14.0</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>10258</td>\n","      <td>3.333333</td>\n","      <td>9</td>\n","      <td>2</td>\n","      <td>10</td>\n","      <td>308</td>\n","      <td>557</td>\n","      <td>1946</td>\n","      <td>1389.0</td>\n","      <td>...</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>5.9</td>\n","      <td>1187899</td>\n","      <td>train</td>\n","      <td>14.0</td>\n","      <td>0.9</td>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>10326</td>\n","      <td>5.000000</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>1003</td>\n","      <td>1923</td>\n","      <td>5526</td>\n","      <td>3603.0</td>\n","      <td>...</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>5.9</td>\n","      <td>1187899</td>\n","      <td>train</td>\n","      <td>14.0</td>\n","      <td>0.1</td>\n","      <td>5</td>\n","      <td>0.166667</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>12427</td>\n","      <td>3.300000</td>\n","      <td>10</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>889</td>\n","      <td>1679</td>\n","      <td>6476</td>\n","      <td>4797.0</td>\n","      <td>...</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>5.9</td>\n","      <td>1187899</td>\n","      <td>train</td>\n","      <td>14.0</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>13032</td>\n","      <td>6.333333</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>10</td>\n","      <td>617</td>\n","      <td>1286</td>\n","      <td>3751</td>\n","      <td>2465.0</td>\n","      <td>...</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>5.9</td>\n","      <td>1187899</td>\n","      <td>train</td>\n","      <td>14.0</td>\n","      <td>0.3</td>\n","      <td>0</td>\n","      <td>0.333333</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 27 columns</p>\n","</div>"],"text/plain":["   user_id  product_id  _up_average_cart_position  _up_order_count  \\\n","0        1         196                   1.400000               10   \n","1        1       10258                   3.333333                9   \n","2        1       10326                   5.000000                1   \n","3        1       12427                   3.300000               10   \n","4        1       13032                   6.333333                3   \n","\n","   _up_first_order_number  _up_last_order_number  \\\n","0                       1                     10   \n","1                       2                     10   \n","2                       5                      5   \n","3                       1                     10   \n","4                       2                     10   \n","\n","   _prod_buy_second_time_total_cnt  _prod_buy_first_time_total_cnt  \\\n","0                             4660                            8000   \n","1                              308                             557   \n","2                             1003                            1923   \n","3                              889                            1679   \n","4                              617                            1286   \n","\n","   _prod_tot_cnts  _prod_reorder_tot_cnts    ...      _user_distinct_products  \\\n","0           35791                 27791.0    ...                           18   \n","1            1946                  1389.0    ...                           18   \n","2            5526                  3603.0    ...                           18   \n","3            6476                  4797.0    ...                           18   \n","4            3751                  2465.0    ...                           18   \n","\n","   _user_reorder_ratio  _user_average_basket  order_id  eval_set  \\\n","0                    0                   5.9   1187899     train   \n","1                    0                   5.9   1187899     train   \n","2                    0                   5.9   1187899     train   \n","3                    0                   5.9   1187899     train   \n","4                    0                   5.9   1187899     train   \n","\n","   time_since_last_order  _up_order_rate  _up_order_since_last_order  \\\n","0                   14.0             1.0                           0   \n","1                   14.0             0.9                           0   \n","2                   14.0             0.1                           5   \n","3                   14.0             1.0                           0   \n","4                   14.0             0.3                           0   \n","\n","   _up_order_rate_since_first_order  reordered  \n","0                          1.000000        1.0  \n","1                          1.000000        1.0  \n","2                          0.166667        NaN  \n","3                          1.000000        NaN  \n","4                          0.333333        1.0  \n","\n","[5 rows x 27 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"yqWd0Agyk3tY","colab_type":"text"},"source":["# Entrenamiento y Generación de los datos de Test\n","\n","##### Xgboost\n","\n","XGBoost es la abreviatura de eXtreme gradient boosting. Es una biblioteca diseñada y optimizada para algoritmos de árbol potenciados.\n","\n","Su objetivo principal es presionar los límites de calculo de las máquinas para proporcionar un escalable, portátil y preciso modo **para impulsar árboles a gran escala**.\n","\n","El término \"**Incremento de degradado**\" se propone en el artículo Acercamiento a la función codiciosa: Una máquina de refuerzo de degradado, por Friedman.\n","\n","XGBoost es un nuevo tipo de algoritmo de impulso que **aprovecha el refuerzo, el diseño de hardware y las penalizaciones del modelo para crear un algoritmo de impulso muy preciso y muy rápido**. Hace que sea una alternativa viable al bosque aleatorio para su uso en aplicaciones predictivas rápidas.\n","\n","**DMatrix es una estructura de datos interna que utiliza XGBoost** que está optimizada tanto para la eficiencia de la memoria como para la velocidad de entrenamiento. Puedes construir DMatrix desde numpy.arrays\n","\n","#### PARAMETROS\n","\n","* data (string / numpy array / scipy.sparse / pd.DataFrame / DataTable) - Fuente de datos de DMatrix. Cuando los datos son de tipo cadena, representan la ruta libsvm en formato txt, o archivo binario desde el que xgboost puede leer.\n","* etiqueta (lista o número 1-D array, opcional) - Etiqueta de los datos de entrenamiento.\n","* faltantes (flotante, opcional): valor en los datos que debe estar presente como un valor faltante. Si Ninguno, el valor predeterminado es np.nan.\n","* ponderación (lista o número 1-D array, opcional) - ponderación para cada instancia.\n","* silencioso (booleano, opcional) - Si se imprimen mensajes durante la construcción\n","* feature_names (lista, opcional) - Establecer nombres para las características.\n","* feature_types (lista, opcional) - Establecer tipos para las características.\n","* nthread (entero, opcional): número de subprocesos que se utilizan para cargar datos desde una matriz numpy. Si -1, utiliza el máximo de hilos disponibles en el sistema."]},{"cell_type":"code","metadata":{"id":"trJXwQymk3tY","colab_type":"code","colab":{},"outputId":"798f4223-e06b-42bc-9fea-501a0c804154"},"source":["#Instalo e importo la librería xgboost: https://xgboost.readthedocs.io/en/latest/python/python_api.html\n","import xgboost\n","\n","train = data.loc[data.eval_set == \"train\",:]\n","train.drop(['eval_set', 'user_id', 'product_id', 'order_id'], axis=1, inplace=True)\n","train.loc[:, 'reordered'] = train.reordered.fillna(0)\n","\n","X_test = data.loc[data.eval_set == \"test\",:]\n","\n","# Submuestra de entrenamiento\n","X_train, X_val, y_train, y_val = train_test_split(train.drop('reordered', axis=1), train.reordered,\n","                                                    test_size=0.9, random_state=42)\n","d_train = xgboost.DMatrix(X_train, y_train)\n","# Parametros que le paso a xgb\n","xgb_params = {\n","    \"objective\"         : \"reg:logistic\"\n","    ,\"eval_metric\"      : \"logloss\"\n","    ,\"eta\"              : 0.1\n","    ,\"max_depth\"        : 6\n","    ,\"min_child_weight\" :10\n","    ,\"gamma\"            :0.70\n","    ,\"subsample\"        :0.76\n","    ,\"colsample_bytree\" :0.95\n","    ,\"alpha\"            :2e-05\n","    ,\"lambda\"           :10\n","}\n","\n","watchlist= [(d_train, \"train\")]\n","bst = xgboost.train(params=xgb_params, dtrain=d_train, num_boost_round=80, evals=watchlist, verbose_eval=10)\n","xgboost.plot_importance(bst)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["C:\\Users\\alejandro.ortega.or1\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  \"\"\"\n","C:\\Users\\alejandro.ortega.or1\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  self.obj[item] = s\n"],"name":"stderr"},{"output_type":"stream","text":["[20:03:15] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n","[0]\ttrain-logloss:0.625588\n","[20:03:17] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n","[20:03:19] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n","[20:03:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 116 extra nodes, 0 pruned nodes, max_depth=6\n","[20:03:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n","[20:03:24] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 4 pruned nodes, max_depth=6\n","[20:03:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 4 pruned nodes, max_depth=6\n","[20:03:28] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n","[20:03:30] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n","[20:03:32] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 116 extra nodes, 0 pruned nodes, max_depth=6\n","[20:03:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 120 extra nodes, 0 pruned nodes, max_depth=6\n","[10]\ttrain-logloss:0.33519\n","[20:03:36] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 122 extra nodes, 0 pruned nodes, max_depth=6\n","[20:03:37] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 116 extra nodes, 0 pruned nodes, max_depth=6\n","[20:03:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n","[20:03:41] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 122 extra nodes, 0 pruned nodes, max_depth=6\n","[20:03:43] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 2 pruned nodes, max_depth=6\n","[20:03:45] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 122 extra nodes, 0 pruned nodes, max_depth=6\n","[20:03:47] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 120 extra nodes, 4 pruned nodes, max_depth=6\n","[20:03:50] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 4 pruned nodes, max_depth=6\n","[20:03:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 4 pruned nodes, max_depth=6\n","[20:03:55] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 120 extra nodes, 2 pruned nodes, max_depth=6\n","[20]\ttrain-logloss:0.268211\n","[20:03:58] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 4 pruned nodes, max_depth=6\n","[20:04:00] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 2 pruned nodes, max_depth=6\n","[20:04:02] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 124 extra nodes, 0 pruned nodes, max_depth=6\n","[20:04:04] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 124 extra nodes, 2 pruned nodes, max_depth=6\n","[20:04:05] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 120 extra nodes, 0 pruned nodes, max_depth=6\n","[20:04:08] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 120 extra nodes, 0 pruned nodes, max_depth=6\n","[20:04:10] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n","[20:04:12] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n","[20:04:13] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n","[20:04:15] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n","[30]\ttrain-logloss:0.251004\n","[20:04:17] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n","[20:04:19] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 2 pruned nodes, max_depth=6\n","[20:04:20] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 116 extra nodes, 2 pruned nodes, max_depth=6\n","[20:04:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 116 extra nodes, 6 pruned nodes, max_depth=6\n","[20:04:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 2 pruned nodes, max_depth=6\n","[20:04:26] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 122 extra nodes, 2 pruned nodes, max_depth=6\n","[20:04:28] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 2 pruned nodes, max_depth=6\n","[20:04:30] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 122 extra nodes, 0 pruned nodes, max_depth=6\n","[20:04:31] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 6 pruned nodes, max_depth=6\n","[20:04:33] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n","[40]\ttrain-logloss:0.246339\n","[20:04:35] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 4 pruned nodes, max_depth=6\n","[20:04:36] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 2 pruned nodes, max_depth=6\n","[20:04:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 4 pruned nodes, max_depth=6\n","[20:04:41] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 4 pruned nodes, max_depth=6\n","[20:04:43] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 2 pruned nodes, max_depth=6\n","[20:04:44] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 122 extra nodes, 0 pruned nodes, max_depth=6\n","[20:04:46] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n","[20:04:48] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 2 pruned nodes, max_depth=6\n","[20:04:50] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n","[20:04:52] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 2 pruned nodes, max_depth=6\n","[50]\ttrain-logloss:0.244771\n","[20:04:54] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 2 pruned nodes, max_depth=6\n","[20:04:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n"],"name":"stdout"},{"output_type":"stream","text":["[20:04:58] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 4 pruned nodes, max_depth=6\n","[20:05:01] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 4 pruned nodes, max_depth=6\n","[20:05:04] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n","[20:05:07] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n","[20:05:09] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 4 pruned nodes, max_depth=6\n","[20:05:11] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 4 pruned nodes, max_depth=6\n","[20:05:14] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n","[20:05:16] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n","[60]\ttrain-logloss:0.24393\n","[20:05:19] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 2 pruned nodes, max_depth=6\n","[20:05:21] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 120 extra nodes, 0 pruned nodes, max_depth=6\n","[20:05:23] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 2 pruned nodes, max_depth=6\n","[20:05:25] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=6\n","[20:05:27] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 2 pruned nodes, max_depth=6\n","[20:05:30] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=6\n","[20:05:32] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 2 pruned nodes, max_depth=6\n","[20:05:34] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 0 pruned nodes, max_depth=6\n","[20:05:36] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 0 pruned nodes, max_depth=6\n","[20:05:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 120 extra nodes, 0 pruned nodes, max_depth=6\n","[70]\ttrain-logloss:0.24336\n","[20:05:41] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=6\n","[20:05:44] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 2 pruned nodes, max_depth=6\n","[20:05:46] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=6\n","[20:05:49] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n","[20:05:51] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 0 pruned nodes, max_depth=6\n","[20:05:53] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n","[20:05:56] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 116 extra nodes, 2 pruned nodes, max_depth=6\n","[20:05:58] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 80 extra nodes, 2 pruned nodes, max_depth=6\n","[20:06:00] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n","[79]\ttrain-logloss:0.242865\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x1cd67898>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"trdrCQpek3ta","colab_type":"code","colab":{},"outputId":"5e927d5c-674d-448e-83cf-f8ad460006d3"},"source":["#train.head(5)\n","#X_test.head(5)\n","#watchlist\n","xgb_params"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'alpha': 2e-05,\n"," 'colsample_bytree': 0.95,\n"," 'eta': 0.1,\n"," 'eval_metric': 'logloss',\n"," 'gamma': 0.7,\n"," 'lambda': 10,\n"," 'max_depth': 6,\n"," 'min_child_weight': 10,\n"," 'objective': 'reg:logistic',\n"," 'subsample': 0.76}"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"eGLY7bOEk3tc","colab_type":"text"},"source":["#### Asunciones y explicación de la predicción\n","Despues de realizar varias pruebas, el modelo más optimo es en el que asumo que el producto será reordenado por el usario si la predicción obtenida es superior a 0,21"]},{"cell_type":"code","metadata":{"id":"0ypD_w-Bk3td","colab_type":"code","colab":{},"outputId":"4a7d0ac1-a586-418c-898f-447fb5931e47"},"source":["d_test = xgboost.DMatrix(X_test.drop(['eval_set', 'user_id', 'order_id', 'reordered', 'product_id'], axis=1))\n","# Si la predicción d_test es superior a 0.21 asumo que es probable que el producto sea reordenado\n","X_test.loc[:,'reordered'] = (bst.predict(d_test) > 0.21).astype(int)\n","X_test.loc[:, 'product_id'] = X_test.product_id.astype(str)\n","\n","# Uso la funcion N Vs 1 para añadir los valores\n","submit = ka_add_groupby_features_n_vs_1(X_test[X_test.reordered == 1], \n","                                               group_columns_list=['order_id'],\n","                                               target_columns_list= ['product_id'],\n","                                               methods_list=[lambda x: ' '.join(set(x))], keep_only_stats=True)\n","submit.columns = sample_submission.columns.tolist()\n","submit_final = sample_submission[['order_id']].merge(submit, how='left').fillna('None')\n","\n","# Por último genero el fichero de salida con lo resultados a entregar: python_test.csv\n","submit_final.to_csv(\"python_test.csv\", index=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["add stats features begin ......\n","add stats features end ......\n","time lapsing 1.80999994278 s \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ygtarjs-k3tf","colab_type":"code","colab":{}},"source":["# Tabla con los datos usados para la predicción\n","X_test.to_csv(\"tabla_prediccion.csv\", index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvPdGtDrk3th","colab_type":"code","colab":{}},"source":["# Array con las predicciones de los productos\n","predict = bst.predict(d_test)\n","np.savetxt('predicciones.txt', predict, delimiter=';') "],"execution_count":0,"outputs":[]}]}